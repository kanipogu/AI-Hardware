Week 2 – Challenge 8

Aim:
To implement and train a simple neural network to solve XOR – a classic nonlinear problem.

Problems:
- Chose wrong activation initially; ReLU doesn’t work well with XOR.
- Training loss wasn’t plotted in early versions, making it hard to debug learning progress.

Final Outcome:
- Trained 2-layer NN and output files like training_loss_curve.png and xor_outputs.txt.

What I Learned:
- Importance of hidden layers in solving nonlinearly separable problems.
- How loss functions and activation functions interact.

How to Run:
python Challenge8.py

